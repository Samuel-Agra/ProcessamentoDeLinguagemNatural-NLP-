{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2025-12-17T14:03:47.032513Z",
     "start_time": "2025-12-17T14:03:47.028390Z"
    }
   },
   "source": [
    "import os\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "from decimal import Decimal, getcontext\n",
    "from skimage.metrics import peak_signal_noise_ratio as psnr\n",
    "import time\n",
    "import heapq\n",
    "import matplotlib.pyplot as plt\n"
   ],
   "outputs": [],
   "execution_count": 56
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "Nesta etapa inicial, as imagens utilizadas no experimento são carregadas e preparadas para o processo de compressão. As imagens são lidas a partir do disco utilizando a biblioteca Pillow, convertidas para escala de cinza e redimensionadas para um tamanho fixo de 255×255 pixels. Essa padronização é necessária para garantir uniformidade durante a análise estatística e a aplicação dos algoritmos de compressão.\n",
    "\n",
    "Após o carregamento, cada imagem é representada como uma matriz NumPy de valores inteiros de 8 bits, correspondentes aos níveis de cinza entre 0 e 255. Em seguida, é gerado o histograma de símbolos de cada imagem, contabilizando a frequência de ocorrência de cada nível de intensidade. A partir desses histogramas, calcula-se a entropia de Shannon, que fornece uma estimativa teórica do limite inferior da compressão sem perdas."
   ],
   "id": "229556c30b3fa714"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-17T14:03:47.059543Z",
     "start_time": "2025-12-17T14:03:47.043328Z"
    }
   },
   "cell_type": "code",
   "source": [
    "#1. Seleção e Preparação das imagens para compressão:\n",
    "\n",
    "# Caminho local onde as imagens de teste foram armazenadas.\n",
    "# As imagens utilizadas neste projeto foram previamente baixadas manualmente\n",
    "# e salvas neste diretório específico. Esse caminho pode (e deve) ser alterado\n",
    "# conforme o ambiente de execução, sistema operacional ou método de obtenção\n",
    "# das imagens (download automático, outro diretório, outro computador, etc.).\n",
    "path = r\"C:\\Users\\user\\programação\\.idea\"\n",
    "\n",
    "imgs = load_imagens(img_names, path)\n",
    "hists = hist_simbolos(imgs)\n",
    "\n",
    "img_names = [\"kodim23t.jpg\",\n",
    "       \"kodim22t.jpg\",\n",
    "       \"kodim21t.jpg\",\n",
    "       \"kodim20t.jpg\",\n",
    "       \"kodim19t.jpg\",\n",
    "       \"kodim17t.jpg\",\n",
    "       \"kodim13t.jpg\",\n",
    "       \"kodim06t.jpg\",\n",
    "       \"kodim05t.jpg\",\n",
    "       \"kodim02t.jpg\"]\n",
    "#Carregando imagens em escala de cinza e matriz uint8\n",
    "def load_imagens(img_names, path, size=(255, 255)):\n",
    "    imgs = []\n",
    "    for filenames in img_names:\n",
    "        img = Image.open(os.path.join(path, filenames)).convert(\"L\")\n",
    "        #imagens precisa de mesmo tamanho para não ocorrer erro no \"histogram2d\"\n",
    "        img = img.resize(size)\n",
    "        imgs.append(np.array(img, dtype = np.uint8))\n",
    "    return imgs\n",
    "\n",
    "#Gerando histograma de símbolos para as imagens\n",
    "def hist_simbolos(imgs):\n",
    "    hists = []\n",
    "    for img in imgs:\n",
    "        pixels = img.flatten()\n",
    "        hist = np.bincount(pixels, minlength=256)\n",
    "        hists.append(hist)\n",
    "    return hists\n",
    "\n",
    "#Calculando entropia das imagens\n",
    "def calcular_entropia(hists):\n",
    "    entropias = []\n",
    "    for hist in hists:\n",
    "        prob = hist / hist.sum()\n",
    "        prob_nonzero = prob[prob > 0]\n",
    "        H = -np.sum(prob_nonzero * np.log2(prob_nonzero))\n",
    "        entropias.append(H)\n",
    "    return entropias\n"
   ],
   "id": "bbf77fd1674fb35f",
   "outputs": [],
   "execution_count": 57
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Nesta seção são implementados os algoritmos de compressão sem perdas utilizados no trabalho: a codificação aritmética e a codificação de Huffman.",
   "id": "b7e59b6d6d19eed0"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "A codificação aritmética baseia-se na atribuição de intervalos cumulativos proporcionais à probabilidade de ocorrência dos símbolos. A sequência completa de dados é representada por um único número real dentro de um intervalo progressivamente refinado. Para isso, são construídas tabelas de probabilidade a partir das frequências dos símbolos observados na imagem.",
   "id": "6766f8e183f62205"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-17T14:03:47.079834Z",
     "start_time": "2025-12-17T14:03:47.067643Z"
    }
   },
   "cell_type": "code",
   "source": [
    "#2. Implementar os Algoritmos de Compressão: Codificação aritmética\n",
    "hist = hists[0]\n",
    "\n",
    "frequency_table = {\n",
    "    i: int(hist[i])\n",
    "    for i in range(256)\n",
    "    if hist[i] > 0\n",
    "}\n",
    "\n",
    "#Codificação Aritmética\n",
    "class ArithmeticEncoding:\n",
    "\n",
    "    #Construtor da codificação AE\n",
    "    def __init__(self, frequency_table):\n",
    "        self.probability_table = self.get_probability_table(frequency_table)\n",
    "\n",
    "#Divide a frequência de cada símbolo pela soma de todas as frequências na tabela\n",
    "def get_probability_table(self, frequency_table):\n",
    "    total_frequency = sum(frequency_table.values())\n",
    "    probability_table = {}\n",
    "    for key in sorted(frequency_table.keys()):\n",
    "        probability_table[key] = frequency_table[key] / total_frequency\n",
    "    return probability_table\n",
    "\n",
    "#Codificador\n",
    "def encode(self, msg, probability_table):\n",
    "    encoder = []\n",
    "    stage_min = Decimal(0.0)\n",
    "    stage_max = Decimal(1.0)\n",
    "    for msg_term_idx in range(len(msg)):\n",
    "        stage_probs = self.process_stage(probability_table, stage_min, stage_max)\n",
    "        msg_term = msg[msg_term_idx]\n",
    "        stage_min = stage_probs[msg_term][0]\n",
    "        stage_max = stage_probs[msg_term][1]\n",
    "        encoder.append(stage_probs)\n",
    "    stage_probs = self.process_stage(probability_table, stage_min, stage_max)\n",
    "    encoder.append(stage_probs)\n",
    "    encoded_msg = self.get_encoded_value(encoder)\n",
    "    return encoder, encoded_msg\n",
    "\n",
    "#Decodificador\n",
    "def decode(self, encoded_msg, msg_length, probability_table):\n",
    "    decoder = []\n",
    "    decoded_msg = []\n",
    "    stage_min = Decimal(0.0)\n",
    "    stage_max = Decimal(1.0)\n",
    "    for idx in range(msg_length):\n",
    "        stage_probs = self.process_stage(probability_table, stage_min, stage_max)\n",
    "        for msg_term in sorted(stage_probs.keys()):\n",
    "            value = stage_probs[msg_term]\n",
    "            if encoded_msg >= value[0] and encoded_msg <= value[1]:\n",
    "                break\n",
    "        decoded_msg.append(msg_term)\n",
    "        stage_min = stage_probs[msg_term][0]\n",
    "        stage_max = stage_probs[msg_term][1]\n",
    "        decoder.append(stage_probs)\n",
    "    stage_probs = self.process_stage(probability_table, stage_min, stage_max)\n",
    "    decoder.append(stage_probs)\n",
    "    return decoder, decoded_msg"
   ],
   "id": "3b68f26ffc5325cc",
   "outputs": [],
   "execution_count": 58
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "A codificação de Huffman, por sua vez, utiliza um método de codificação por comprimento variável baseado na construção de uma árvore binária ótima. Símbolos mais frequentes recebem códigos binários menores, enquanto símbolos menos frequentes recebem códigos maiores, garantindo a propriedade de prefixo e a minimização do comprimento médio do código.",
   "id": "25c64e797b530863"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-17T14:03:47.096076Z",
     "start_time": "2025-12-17T14:03:47.088684Z"
    }
   },
   "cell_type": "code",
   "source": [
    "#2. Implementar os Algoritmos de Compressão: Huffman\n",
    "\n",
    "#Codificação de Huffman\n",
    "class HuffmanNode:\n",
    "\n",
    "    #Construtor da codifição de Huffman\n",
    "    def __init__(self, symbol=None, freq=0):\n",
    "        self.symbol = symbol\n",
    "        self.freq = freq\n",
    "        self.left = None\n",
    "        self.right = None\n",
    "\n",
    "    def __lt__(self, other):\n",
    "        return self.freq < other.freq\n",
    "\n",
    "#Construção da arvode de Huffman\n",
    "def build_huffman_tree(frequency_table):\n",
    "    heap = []\n",
    "    for symbol, freq in frequency_table.items():\n",
    "        heapq.heappush(heap, HuffmanNode(symbol, freq))\n",
    "    while len(heap) > 1:\n",
    "        node1 = heapq.heappop(heap)\n",
    "        node2 = heapq.heappop(heap)\n",
    "        merged = HuffmanNode(freq=node1.freq + node2.freq)\n",
    "        merged.left = node1\n",
    "        merged.right = node2\n",
    "        heapq.heappush(heap, merged)\n",
    "    return heap[0]\n",
    "\n",
    "#Gerador da arvore de Huffman\n",
    "def generate_huffman_codes(node, prefix=\"\", codebook=None):\n",
    "    if codebook is None:\n",
    "        codebook = {}\n",
    "    if node.symbol is not None:\n",
    "        codebook[node.symbol] = prefix\n",
    "        return codebook\n",
    "    generate_huffman_codes(node.left, prefix + \"0\", codebook)\n",
    "    generate_huffman_codes(node.right, prefix + \"1\", codebook)\n",
    "    return codebook\n",
    "\n",
    "#Huffman codificação\n",
    "def huffman_encode(img, codebook):\n",
    "    flat = img.flatten()\n",
    "    encoded_bits = \"\".join(codebook[pixel] for pixel in flat)\n",
    "    return encoded_bits\n",
    "\n",
    "#Huffman decodificação\n",
    "def huffman_decode(encoded_bits, root, shape):\n",
    "    decoded = []\n",
    "    node = root\n",
    "    for bit in encoded_bits:\n",
    "        node = node.left if bit == \"0\" else node.right\n",
    "        if node.symbol is not None:\n",
    "            decoded.append(node.symbol)\n",
    "            node = root\n",
    "    return np.array(decoded, dtype=np.uint8).reshape(shape)\n"
   ],
   "id": "3737cfb443d2afad",
   "outputs": [],
   "execution_count": 59
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Ambos os algoritmos operam diretamente sobre os valores dos pixels, considerados como símbolos de uma fonte discreta.",
   "id": "c1c702d80e055947"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "O pipeline geral de compressão segue uma sequência estruturada de etapas, aplicada individualmente a cada imagem do conjunto de dados. Inicialmente, a imagem é recebida como uma matriz bidimensional de pixels em escala de cinza. Em seguida, essa matriz é transformada em um vetor unidimensional, permitindo o tratamento da imagem como uma sequência linear de símbolos.\n",
    "\n",
    "A partir desse vetor, calcula-se a distribuição de probabilidade dos símbolos, que é utilizada para a construção do codificador de Huffman. O vetor de pixels é então codificado, gerando um bitstream comprimido. Posteriormente, esse bitstream é decodificado utilizando a mesma árvore de Huffman, permitindo a reconstrução da imagem original.\n",
    "\n",
    "Por se tratar de um método de compressão sem perdas, a imagem reconstruída é idêntica à imagem original, o que é verificado ao final do processo."
   ],
   "id": "eac2765ff32ddaae"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-17T14:03:47.298788Z",
     "start_time": "2025-12-17T14:03:47.103204Z"
    }
   },
   "cell_type": "code",
   "source": [
    "#3. Pipeline Geral de Compressão\n",
    "imgs = load_imagens(img_names, path)\n",
    "\n",
    "for idx, img_array in enumerate(imgs):\n",
    "    img_name = img_names[idx]\n",
    "\n",
    "    #\"Entrada\"\n",
    "    original_shape = img_array.shape\n",
    "\n",
    "    #\"Flattening\"\n",
    "    pixels_1d = img_array.flatten()\n",
    "\n",
    "    #\"Cálculo da distribuição de probabilidade\"\n",
    "    hist = np.bincount(pixels_1d, minlength=256)\n",
    "    frequency_table = {\n",
    "        symbol: int(freq)\n",
    "        for symbol, freq in enumerate(hist)\n",
    "        if freq > 0\n",
    "    }\n",
    "\n",
    "    #\"Construção do codificador\"\n",
    "    root = build_huffman_tree(frequency_table)\n",
    "    huffman_codes = generate_huffman_codes(root)\n",
    "\n",
    "    #\"Codificação do vetor de pixels\"\n",
    "    bitstream = huffman_encode(img_array, huffman_codes)\n",
    "\n",
    "    #\"Geração do bitstream comprimido\"\n",
    "    compressed_size_bits = len(bitstream)\n",
    "\n",
    "    #\"Decodificação reversa\" - \"Reconstrução da imagem\"\n",
    "    reconstructed_img = huffman_decode(bitstream, root, original_shape)"
   ],
   "id": "8d85632243092da9",
   "outputs": [],
   "execution_count": 60
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "A análise dos resultados é realizada por meio de métricas quantitativas que avaliam a eficiência e a qualidade do processo de compressão. A taxa de compressão é calculada comparando o número de bits necessários para representar a imagem original com o número de bits gerados após a codificação.\n",
    "\n",
    "A qualidade da imagem reconstruída é avaliada por meio do PSNR (Peak Signal-to-Noise Ratio). Como os métodos de compressão implementados são sem perdas, o erro quadrático médio entre a imagem original e a reconstruída é nulo, resultando em um PSNR teoricamente infinito.\n",
    "\n",
    "Além disso, o tempo de processamento é medido para avaliar o custo computacional da compressão. Para fins de comparação, também é considerada a compressão JPEG, utilizando as funções nativas da biblioteca Pillow."
   ],
   "id": "29b1f8bdeb8e21a"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-17T14:03:47.512157Z",
     "start_time": "2025-12-17T14:03:47.305498Z"
    }
   },
   "cell_type": "code",
   "source": [
    "#4. Análise e Comparação:\n",
    "\n",
    "#Calcular a Taxa de Compressão\n",
    "def calculate_file_size(file_path):\n",
    "    \"\"\"Calcula o tamanho do arquivo em bytes.\"\"\"\n",
    "    return os.path.getsize(file_path)\n",
    "\n",
    "def calculate_compression_ratio_array(original_img, bitstream):\n",
    "    original_bits = original_img.size * 8\n",
    "    compressed_bits = len(bitstream)\n",
    "    return original_bits / compressed_bits\n",
    "\n",
    "#Avaliar a Qualidade da Imagem\n",
    "def calculate_psnr_array(original_img, reconstructed_img):\n",
    "    mse = np.mean((original_img.astype(np.float64) - reconstructed_img.astype(np.float64)) ** 2)\n",
    "    if mse == 0:\n",
    "        return float(\"inf\")\n",
    "    max_pixel = 255.0\n",
    "    return 10 * log10((max_pixel ** 2) / mse)\n",
    "\n",
    "#Medir o Tempo de Processamento\n",
    "def measure_time(function, *args):\n",
    "    start = time.time()\n",
    "    result = function(*args)\n",
    "    end = time.time()\n",
    "    return result, end - start\n",
    "\n",
    "#Testes\n",
    "def compress_image(input_path, output_path, quality):\n",
    "    img = Image.open(input_path)\n",
    "    img.save(output_path, 'JPEG', quality=quality)\n",
    "\n",
    "for idx, img_array in enumerate(imgs):\n",
    "    img_name = img_names[idx]\n",
    "\n",
    "    original_shape = img_array.shape\n",
    "    pixels_1d = img_array.flatten()\n",
    "\n",
    "    hist = np.bincount(pixels_1d, minlength=256)\n",
    "    frequency_table = {\n",
    "        symbol: int(freq)\n",
    "        for symbol, freq in enumerate(hist)\n",
    "        if freq > 0\n",
    "    }\n",
    "\n",
    "    # Tempo de compressão\n",
    "    (bitstream, root), comp_time = measure_time(\n",
    "        lambda img: (\n",
    "            huffman_encode(img, generate_huffman_codes(build_huffman_tree(frequency_table))),\n",
    "            build_huffman_tree(frequency_table)\n",
    "        ),\n",
    "        img_array\n",
    "    )\n",
    "\n",
    "    reconstructed_img = huffman_decode(bitstream, root, original_shape)\n",
    "\n",
    "    compression_ratio = calculate_compression_ratio_array(img_array, bitstream)\n",
    "    psnr_value = calculate_psnr_array(img_array, reconstructed_img)\n",
    "\n",
    "    print(f\"Imagem: {img_name}\")\n",
    "    print(f\"Taxa de Compressão: {compression_ratio:.2f}\")\n",
    "    print(f\"PSNR: {psnr_value:.2f} dB\")\n",
    "    print(f\"Tempo de Compressão: {comp_time:.4f} s\\n\")"
   ],
   "id": "576832222d9942ff",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Imagem: kodim23t.jpg\n",
      "Taxa de Compressão: 1.24\n",
      "PSNR: inf dB\n",
      "Tempo de Compressão: 0.0047 s\n",
      "\n",
      "Imagem: kodim22t.jpg\n",
      "Taxa de Compressão: 1.25\n",
      "PSNR: inf dB\n",
      "Tempo de Compressão: 0.0047 s\n",
      "\n",
      "Imagem: kodim21t.jpg\n",
      "Taxa de Compressão: 1.27\n",
      "PSNR: inf dB\n",
      "Tempo de Compressão: 0.0088 s\n",
      "\n",
      "Imagem: kodim20t.jpg\n",
      "Taxa de Compressão: 1.35\n",
      "PSNR: inf dB\n",
      "Tempo de Compressão: 0.0049 s\n",
      "\n",
      "Imagem: kodim19t.jpg\n",
      "Taxa de Compressão: 1.24\n",
      "PSNR: inf dB\n",
      "Tempo de Compressão: 0.0049 s\n",
      "\n",
      "Imagem: kodim17t.jpg\n",
      "Taxa de Compressão: 1.22\n",
      "PSNR: inf dB\n",
      "Tempo de Compressão: 0.0048 s\n",
      "\n",
      "Imagem: kodim13t.jpg\n",
      "Taxa de Compressão: 1.22\n",
      "PSNR: inf dB\n",
      "Tempo de Compressão: 0.0046 s\n",
      "\n",
      "Imagem: kodim06t.jpg\n",
      "Taxa de Compressão: 1.22\n",
      "PSNR: inf dB\n",
      "Tempo de Compressão: 0.0061 s\n",
      "\n",
      "Imagem: kodim05t.jpg\n",
      "Taxa de Compressão: 1.23\n",
      "PSNR: inf dB\n",
      "Tempo de Compressão: 0.0047 s\n",
      "\n",
      "Imagem: kodim02t.jpg\n",
      "Taxa de Compressão: 1.49\n",
      "PSNR: inf dB\n",
      "Tempo de Compressão: 0.0048 s\n",
      "\n"
     ]
    }
   ],
   "execution_count": 61
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "Os resultados obtidos demonstram que a codificação de Huffman é capaz de reduzir significativamente o tamanho dos dados, aproximando-se do limite teórico imposto pela entropia da fonte. Observa-se que imagens com maior redundância apresentam taxas de compressão mais elevadas.\n",
    "\n",
    "Em comparação com o método JPEG, a compressão por Huffman preserva integralmente a informação da imagem, ao custo de taxas de compressão geralmente menores. Essa diferença é esperada, uma vez que o JPEG utiliza técnicas com perdas baseadas em transformadas e quantização."
   ],
   "id": "bc5c04295424d0cf"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
